{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 人脸检测和识别训练流程\n",
    "\n",
    "以下示例展示了如何在自己的数据集上微调InceptionResnetV1模型。这将主要遵循标准的PyTorch训练模式。"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-26T13:37:09.056641Z",
     "start_time": "2024-06-26T13:37:07.967250Z"
    }
   },
   "source": [
    "from pathlib import Path\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1, fixed_image_standardization, training\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义运行参数\n",
    "\n",
    "数据集应该遵循VGGFace2/ImageNet风格的目录布局。将`data_dir`修改为您要微调的数据集所在的位置。"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-26T13:37:09.059669Z",
     "start_time": "2024-06-26T13:37:09.057679Z"
    }
   },
   "source": [
    "root_dir = Path(Path(__file__).parent if \"__file__\" in globals() else \"\").absolute().parent\n",
    "data_dir = root_dir / \"tests\" / \"data\" / \"test_images\"\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 8\n",
    "workers = 0 if os.name == \"nt\" else 8"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 判断是否有nvidia GPU可用"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-26T13:37:09.098410Z",
     "start_time": "2024-06-26T13:37:09.060230Z"
    }
   },
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"在该设备上运行: {}\".format(device))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在该设备上运行: cuda:0\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义MTCNN模块\n",
    "\n",
    "查看`help(MTCNN)`获取更多细节。"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-26T13:37:09.171504Z",
     "start_time": "2024-06-26T13:37:09.099016Z"
    }
   },
   "source": [
    "mtcnn = MTCNN(\n",
    "    image_size=160, margin=0, min_face_size=20,\n",
    "    thresholds=[0.6, 0.7, 0.7], factor=0.709, post_process=True,\n",
    "    device=device\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 执行MTCNN人脸检测\n",
    "\n",
    "迭代DataLoader对象并获取裁剪后的人脸。"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-06-26T13:37:09.786825Z",
     "start_time": "2024-06-26T13:37:09.172806Z"
    }
   },
   "source": [
    "dataset = datasets.ImageFolder(data_dir, transform=transforms.Resize((512, 512)))\n",
    "dataset.samples = [\n",
    "    (p, p.replace(str(data_dir), str(data_dir.parent / (data_dir.name + \"_aligned\"))))\n",
    "        for p, _ in dataset.samples\n",
    "]\n",
    "        \n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    num_workers=workers,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=training.collate_pil\n",
    ")\n",
    "\n",
    "for i, (x, y) in enumerate(loader):\n",
    "    mtcnn(x, save_path=y)\n",
    "    print(f\"\\r第 {i + 1} 批，共 {len(loader)} 批\", end=\"\")\n",
    "    \n",
    "# Remove mtcnn to reduce GPU memory usage\n",
    "del mtcnn"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 1 批，共 1 批"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义Inception Resnet V1模块\n",
    "\n",
    "查看`help(InceptionResnetV1)`获取更多细节。"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-26T13:37:10.001554Z",
     "start_time": "2024-06-26T13:37:09.787672Z"
    }
   },
   "source": [
    "resnet = InceptionResnetV1(\n",
    "    classify=True,\n",
    "    pretrained=\"vggface2\",\n",
    "    num_classes=len(dataset.class_to_idx)\n",
    ").to(device)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义优化器、调度器、数据集和数据加载器"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-26T13:37:10.006715Z",
     "start_time": "2024-06-26T13:37:10.002495Z"
    }
   },
   "source": [
    "optimizer = optim.Adam(resnet.parameters(), lr=0.001)\n",
    "scheduler = MultiStepLR(optimizer, [5, 10])\n",
    "\n",
    "trans = transforms.Compose([\n",
    "    np.float32,\n",
    "    transforms.ToTensor(),\n",
    "    fixed_image_standardization\n",
    "])\n",
    "dataset = datasets.ImageFolder(data_dir.parent / (data_dir.name + \"_aligned\"), transform=trans)\n",
    "img_inds = np.arange(len(dataset))\n",
    "np.random.shuffle(img_inds)\n",
    "train_inds = img_inds[:int(0.8 * len(img_inds))]\n",
    "val_inds = img_inds[int(0.8 * len(img_inds)):]\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset,\n",
    "    num_workers=workers,\n",
    "    batch_size=batch_size,\n",
    "    sampler=SubsetRandomSampler(train_inds)\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset,\n",
    "    num_workers=workers,\n",
    "    batch_size=batch_size,\n",
    "    sampler=SubsetRandomSampler(val_inds)\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义损失和评估函数"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-26T13:37:10.009281Z",
     "start_time": "2024-06-26T13:37:10.007416Z"
    }
   },
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "metrics = {\n",
    "    \"fps\": training.BatchTimer(),\n",
    "    \"acc\": training.accuracy\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-26T13:37:12.940318Z",
     "start_time": "2024-06-26T13:37:10.009807Z"
    }
   },
   "source": [
    "writer = SummaryWriter()\n",
    "writer.iteration, writer.interval = 0, 10\n",
    "\n",
    "print(\"\\n\\n初始化\")\n",
    "print(\"-\" * 10)\n",
    "resnet.eval()\n",
    "training.pass_epoch(\n",
    "    resnet, loss_fn, val_loader,\n",
    "    batch_metrics=metrics, show_running=True, device=device,\n",
    "    writer=writer\n",
    ")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n循环 {epoch + 1}/{epochs}\")\n",
    "    print(\"-\" * 10)\n",
    "\n",
    "    resnet.train()\n",
    "    training.pass_epoch(\n",
    "        resnet, loss_fn, train_loader, optimizer, scheduler,\n",
    "        batch_metrics=metrics, show_running=True, device=device,\n",
    "        writer=writer\n",
    "    )\n",
    "\n",
    "    resnet.eval()\n",
    "    training.pass_epoch(\n",
    "        resnet, loss_fn, val_loader,\n",
    "        batch_metrics=metrics, show_running=True, device=device,\n",
    "        writer=writer\n",
    "    )\n",
    "\n",
    "writer.close()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "初始化\n",
      "----------\n",
      "Valid |     1/1    | loss:    1.8712 | fps:    8.0232 | acc:    0.0000   \n",
      "\n",
      "循环 1/8\n",
      "----------\n",
      "Train |     1/1    | loss:    1.8678 | fps:   24.3647 | acc:    0.1250   \n",
      "Valid |     1/1    | loss:    1.2026 | fps:   14.7643 | acc:    0.5000   \n",
      "\n",
      "循环 2/8\n",
      "----------\n",
      "Train |     1/1    | loss:    0.2042 | fps:   50.4942 | acc:    1.0000   \n",
      "Valid |     1/1    | loss:    1.5995 | fps:   12.6769 | acc:    0.5000   \n",
      "\n",
      "循环 3/8\n",
      "----------\n",
      "Train |     1/1    | loss:    0.0218 | fps:   55.0083 | acc:    1.0000   \n",
      "Valid |     1/1    | loss:    2.5796 | fps:   13.2789 | acc:    0.5000   \n",
      "\n",
      "循环 4/8\n",
      "----------\n",
      "Train |     1/1    | loss:    0.0107 | fps:   47.8045 | acc:    1.0000   \n",
      "Valid |     1/1    | loss:    3.2210 | fps:   13.6371 | acc:    0.5000   \n",
      "\n",
      "循环 5/8\n",
      "----------\n",
      "Train |     1/1    | loss:    0.0047 | fps:   50.4422 | acc:    1.0000   \n",
      "Valid |     1/1    | loss:    3.9986 | fps:   13.5192 | acc:    0.5000   \n",
      "\n",
      "循环 6/8\n",
      "----------\n",
      "Train |     1/1    | loss:    0.0015 | fps:   49.3932 | acc:    1.0000   \n",
      "Valid |     1/1    | loss:    1.6270 | fps:   12.4765 | acc:    0.5000   \n",
      "\n",
      "循环 7/8\n",
      "----------\n",
      "Train |     1/1    | loss:    0.0012 | fps:   48.9522 | acc:    1.0000   \n",
      "Valid |     1/1    | loss:    0.5061 | fps:   13.4166 | acc:    0.5000   \n",
      "\n",
      "循环 8/8\n",
      "----------\n",
      "Train |     1/1    | loss:    0.0014 | fps:   47.4795 | acc:    1.0000   \n",
      "Valid |     1/1    | loss:    0.1531 | fps:   12.1058 | acc:    1.0000   \n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
